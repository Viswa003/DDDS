{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\viswa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Step 2: Data Preparation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "metadata = pd.read_csv('HAM10000_metadata.csv')\n",
    "\n",
    "# Balance the dataset using oversampling\n",
    "def balance_dataset(metadata):\n",
    "    class_counts = metadata['dx'].value_counts()\n",
    "    max_class = class_counts.max()\n",
    "    balanced_metadata = metadata.groupby('dx').apply(lambda x: x.sample(max_class, replace=True)).reset_index(drop=True)\n",
    "    return balanced_metadata\n",
    "\n",
    "balanced_metadata = balance_dataset(metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c467fc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Data Preprocessing\n",
    "\n",
    "import cv2\n",
    "\n",
    "def remove_hair(image):\n",
    "    grayScale = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    kernel = cv2.getStructuringElement(1, (17, 17))\n",
    "    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n",
    "    ret, thresh2 = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)\n",
    "    dst = cv2.inpaint(image, thresh2, 1, cv2.INPAINT_TELEA)\n",
    "    return dst\n",
    "\n",
    "# Apply preprocessing to all images\n",
    "def preprocess_images(metadata):\n",
    "    for i, row in metadata.iterrows():\n",
    "        image_path = os.path.join('HAM10000_images', row['image_id'] + '.jpg')\n",
    "        image = cv2.imread(image_path)\n",
    "        image = remove_hair(image)\n",
    "        cv2.imwrite(image_path, image)\n",
    "\n",
    "preprocess_images(balanced_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57a82a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37548 validated image filenames belonging to 7 classes.\n",
      "Found 9387 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Step 4: Data Augmentation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "def create_data_generator(metadata, batch_size=32, img_size=(224, 224)):\n",
    "    train_gen = datagen.flow_from_dataframe(\n",
    "        dataframe=metadata,\n",
    "        directory='HAM10000_images',\n",
    "        x_col='image_id',\n",
    "        y_col='dx',\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        seed=42\n",
    "    )\n",
    "    val_gen = datagen.flow_from_dataframe(\n",
    "        dataframe=metadata,\n",
    "        directory='HAM10000_images',\n",
    "        x_col='image_id',\n",
    "        y_col='dx',\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        seed=42\n",
    "    )\n",
    "    return train_gen, val_gen\n",
    "\n",
    "train_gen, val_gen = create_data_generator(balanced_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a552dd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\viswa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\viswa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "51877672/51877672 [==============================] - 11s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\viswa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\viswa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\viswa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\viswa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  18/1174 [..............................] - ETA: 19:06:00 - loss: 1.9876 - accuracy: 0.3785"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import DenseNet169\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "def build_model(base_model, num_classes):\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "num_classes = balanced_metadata['dx'].nunique()\n",
    "\n",
    "# DenseNet169 Model\n",
    "base_model_densenet = DenseNet169(weights='imagenet', include_top=False)\n",
    "model_densenet = build_model(base_model_densenet, num_classes)\n",
    "\n",
    "# Compile model\n",
    "model_densenet.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callback for reducing learning rate\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "\n",
    "# Train model\n",
    "history_densenet = model_densenet.fit(train_gen, validation_data=val_gen, epochs=50, steps_per_epoch=len(train_gen), validation_steps=len(val_gen), callbacks=[reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc053f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6: Model Evaluation\n",
    "# Evaluate DenseNet169 Model\n",
    "\n",
    "val_loss, val_accuracy = model_densenet.evaluate(val_gen)\n",
    "print(f'DenseNet169 Model Accuracy: {val_accuracy*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebabb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7: Save the Model\n",
    "\n",
    "model_densenet.save('densenet169_skin_cancer_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df5f4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL, Hyperparameter Tuning, Optionally, you can use Keras Tuner for hyperparameter tuning to further optimize the model\n",
    "from keras_tuner import RandomSearch\n",
    "\n",
    "def model_builder(hp):\n",
    "    base_model = DenseNet169(weights='imagenet', include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(hp.Int('units', min_value=512, max_value=2048, step=512), activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(model_builder, objective='val_accuracy', max_trials=5, executions_per_trial=3)\n",
    "tuner.search(train_gen, validation_data=val_gen, epochs=10)\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.fit(train_gen, validation_data=val_gen, epochs=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
